---

title: MetNet Model


keywords: fastai
sidebar: home_sidebar

summary: "Implementation of the parts of the metnet arch from the paper"
description: "Implementation of the parts of the metnet arch from the paper"
nb_path: "01_model.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_model.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we are going to implement the parts of the model <a href="https://arxiv.org/abs/2003.12140">MetNet</a> from "MetNet: A Neural Weather Model for Precipitation Forecasting"</p>
<p><img src="/metnet_pytorch/images/metnet_scheme.png" alt="metenet_scheme"></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Downsampler">Downsampler<a class="anchor-link" href="#Downsampler"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>from the paper, the downsampler blocks are a bunch of convs and maxpooling layers, with out anything fancy, not even activations. From the paper:</p>
<blockquote><p>MetNet aims at fully capturing the spatial context in the input patch. A trade-off arises between the
fidelity of the representation and the memory and computation required to compute it. To maintain
viable memory and computation requirements, the first part of MetNet contracts the input tensor
spatially using a series of convolution and pooling layers. The t slices along the time dimension of
the input patch are processed separately. Each slice is first packaged into an input tensor of spatial
dimensions 256 × 256 (see Appendix A for the exact pre-processing operations). Each slice is then
processed by the following neural network layers:a 3 × 3 convolution with 160 channels, a 2 × 2max-pooling layer with stride 2, three more 3 × 3 convolutions with 256 channels and one more
2 × 2 max pooling layer with stride 2. These operations produce t tensors of spatial dimensions
64 × 64 and 256 channels.</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="DownSampler" class="doc_header"><code>DownSampler</code><a href="https://github.com/tcapelle/metnet_pytorch/tree/master/metnet_pytorch/model.py#L11" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>DownSampler</code>(<strong><code>in_channels</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I put less convs and added <code>nn.BatchNorm2d</code>, as I finally ended up using another image encoder, you can choose anything form torchvision or <a href="https://github.com/rwightman/pytorch-image-models">timm</a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">DownSampler</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">ds</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">,[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>as we can check, it divides by four the spatial resolution,</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Temporal-Encoder">Temporal Encoder<a class="anchor-link" href="#Temporal-Encoder"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The second part of MetNet encodes the input patch along the temporal dimension.  The spatially contracted slices are given to a recurrent neural network following the order of time.   We use a Convolutional Long Short-Term Memory network with kernel size 3×3 and 384 channels for the temporal encoding   (Xingjian et al., 2015).</p>
<p>The result is a single tensor of size 64×64 and 384 channels, where each location summarizes spatially and temporally one region of the large contextin the input patch</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="TemporalEncoder" class="doc_header"><code>class</code> <code>TemporalEncoder</code><a href="https://github.com/tcapelle/metnet_pytorch/tree/master/metnet_pytorch/model.py#L24" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>TemporalEncoder</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>=<em><code>384</code></em>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>n_layers</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">te</span> <span class="o">=</span> <span class="n">TemporalEncoder</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span><span class="n">h</span> <span class="o">=</span> <span class="n">te</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conditioning-on-Target-Lead-Time">Conditioning on Target Lead Time<a class="anchor-link" href="#Conditioning-on-Target-Lead-Time"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The leadtime is represented as an integeri= (Ty/2)−1indicating minutes from 2 to 480.  The integeriis tiled along thew×hlocations in the patch and is represented as an all-zero vector with a 1at positioniin the vector.  By changing the target lead time given as input, one can use the sameMetNet model to make forecasts for the entire range of target times that MetNet is trained on</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seq_len</span><span class="o">=</span><span class="mi">5</span>
<span class="n">i</span><span class="o">=</span><span class="mi">3</span>
<span class="n">times</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">seq_len</span><span class="p">)[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">times</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ones</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([5, 1, 1]), torch.Size([1, 2, 2]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">times</span> <span class="o">*</span> <span class="n">ones</span>
<span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[0., 0.],
         [0., 0.]],

        [[0., 0.],
         [0., 0.]],

        [[1., 1.],
         [1., 1.]],

        [[0., 0.],
         [0., 0.]],

        [[0., 0.],
         [0., 0.]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="condition_time" class="doc_header"><code>condition_time</code><a href="https://github.com/tcapelle/metnet_pytorch/tree/master/metnet_pytorch/model.py#L32" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>condition_time</code>(<strong><code>x</code></strong>, <strong><code>i</code></strong>=<em><code>0</code></em>, <strong><code>size</code></strong>=<em><code>(12, 16)</code></em>, <strong><code>seq_len</code></strong>=<em><code>15</code></em>)</p>
</blockquote>
<p>create one hot encoded time image-layers, i in [1, seq_len]</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Beware, from <code>i=0</code> to <code>i=seq_len-1</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">ct</span> <span class="o">=</span> <span class="n">condition_time</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">16</span><span class="p">),</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">ct</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">12</span><span class="o">*</span><span class="mi">16</span>  <span class="c1">#full of ones</span>
<span class="n">ct</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ct</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([15, 12, 16]),
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ConditionTime" class="doc_header"><code>class</code> <code>ConditionTime</code><a href="https://github.com/tcapelle/metnet_pytorch/tree/master/metnet_pytorch/model.py#L40" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ConditionTime</code>(<strong><code>horizon</code></strong>, <strong><code>ch_dim</code></strong>=<em><code>2</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Condition Time on a stack of images, adds <code>horizon</code> channels to image</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ct</span> <span class="o">=</span> <span class="n">ConditionTime</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ct</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([1, 5, 5, 4, 4])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="feat2image" class="doc_header"><code>feat2image</code><a href="https://github.com/tcapelle/metnet_pytorch/tree/master/metnet_pytorch/model.py#L55" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>feat2image</code>(<strong><code>x</code></strong>, <strong><code>target_size</code></strong>=<em><code>(128, 128)</code></em>)</p>
</blockquote>
<p>This idea comes from MetNet</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">feat2image</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 10, 4, 16, 16])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Temporal-Aggregator">Temporal Aggregator<a class="anchor-link" href="#Temporal-Aggregator"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>To make MetNet’s receptive field cover the full global spatial context in the input patch, the third
part of MetNet uses a series of eight axial self-attention blocks (Ho et al., 2019; Donahue and Si-
monyan, 2019). Four axial self-attention blocks operating along the width and four blocks operating
along the height are interleaved and have 2048 channels and 16 attention heads each</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>please install using pip:</p>
<div class="highlight"><pre><span></span>pip install axial_attention
</pre></div>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">attn</span> <span class="o">=</span> <span class="n">AxialAttention</span><span class="p">(</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>           <span class="c1"># embedding dimension</span>
    <span class="n">dim_index</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>       <span class="c1"># where is the embedding dimension</span>
    <span class="n">heads</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>           <span class="c1"># number of heads for multi-head attention</span>
    <span class="n">num_dimensions</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># number of axial dimensions (images is 2, video is 3, or more)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Model-MetNet">The Model MetNet<a class="anchor-link" href="#The-Model-MetNet"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will build a small model to try the concept first.</p>
<ul>
<li>The model will output all timesteps up to <code>horizon</code>.</li>
<li>We can condition on time before passing the images or after (saving some computations)</li>
<li>To start, we will output a timeseries, so we will put a <code>head</code> that generates one value per timestep. If you don't put any <code>head</code> you get the full attention maps.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MetNet" class="doc_header"><code>class</code> <code>MetNet</code><a href="https://github.com/tcapelle/metnet_pytorch/tree/master/metnet_pytorch/model.py#L64" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MetNet</code>(<strong><code>image_encoder</code></strong>, <strong><code>hidden_dim</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>n_layers</code></strong>=<em><code>1</code></em>, <strong><code>n_att_layers</code></strong>=<em><code>1</code></em>, <strong><code>head</code></strong>=<em><code>None</code></em>, <strong><code>horizon</code></strong>=<em><code>3</code></em>, <strong><code>n_feats</code></strong>=<em><code>0</code></em>, <strong><code>p</code></strong>=<em><code>0.2</code></em>, <strong><code>debug</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Same as <code>nn.Module</code>, but no need for subclasses to call <code>super().__init__</code></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The params are as following:</p>
<ul>
<li><code>image_encoder</code>: A image 2 feature model, can be a VGG for instance.</li>
<li><code>hidden_dim</code>: The channels on the temporal encoder ConvGRU cell.</li>
<li><code>ks</code>: kernel size on the ConvGRU cell.</li>
<li><code>n_layers</code>: Number of ConvGRU cells.</li>
<li><code>n_att_layers</code>: Number of AxialAttention layers on the Temporal Aggregator.</li>
<li><code>ct_first</code>: If we condition time before or after image encoding.</li>
<li><code>head</code>: The head output of the model.</li>
<li><code>horizon</code>: How many timesteps to predict.</li>
<li><code>n_feats</code>: How many features are we passing to the model besides images, they will be encoded as image layers. See appendix of paper.</li>
<li><code>p</code>: Dropout on temporal encoder.</li>
<li><code>debug</code>: If True, prints every intermediary step</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The model is structured with a <code>encode_timestep</code> method to condition on each timestep the input images:</p>
<ul>
<li>First we take the input image sequence and condition on lead time</li>
<li>We pass this augmented image trhough the image_encoder</li>
<li>We apply the temporal encoder and </li>
<li>Finally we do the spatial attention.</li>
</ul>
<p>In the forward method:</p>
<ul>
<li>We encode the numerical features on image channels using <a href="/metnet_pytorch/model.html#feat2image"><code>feat2image</code></a></li>
<li>We stack these with the original image</li>
<li>We iteratively call the <code>encode_timestep</code> and finally we return the predicted vector</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's check:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">horizon</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_feats</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>the <code>image_encoder</code> must take 3 (RGB image) + horizon (for the conditining time) + feats (for the extra data planes added to image)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">image_encoder</span> <span class="o">=</span> <span class="n">DownSampler</span><span class="p">(</span><span class="mi">3</span><span class="o">+</span><span class="n">horizon</span><span class="o">+</span><span class="n">n_feats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">metnet</span> <span class="o">=</span> <span class="n">MetNet</span><span class="p">(</span><span class="n">image_encoder</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
                <span class="n">ks</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">horizon</span><span class="o">=</span><span class="n">horizon</span><span class="p">,</span> 
                <span class="n">head</span><span class="o">=</span><span class="n">create_head</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">n_feats</span><span class="o">=</span><span class="n">n_feats</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>timeseries data, could be other thing that is sequential as the images</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_feats</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">imgs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">metnet</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">feats</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> Input -&gt; (imgs: torch.Size([2, 10, 3, 128, 128]), feats: torch.Size([2, 4, 10]))
 augmented imgs:   torch.Size([2, 10, 7, 128, 128])
Encode Timestep:(i=0)
 input shape: torch.Size([2, 10, 7, 128, 128])
 CondTime-&gt;x.shape: torch.Size([2, 10, 12, 128, 128])
 encoded images shape: torch.Size([2, 10, 256, 32, 32])
 temp_enc out shape: torch.Size([2, 128, 32, 32])
Encode Timestep:(i=1)
 input shape: torch.Size([2, 10, 7, 128, 128])
 CondTime-&gt;x.shape: torch.Size([2, 10, 12, 128, 128])
 encoded images shape: torch.Size([2, 10, 256, 32, 32])
 temp_enc out shape: torch.Size([2, 128, 32, 32])
Encode Timestep:(i=2)
 input shape: torch.Size([2, 10, 7, 128, 128])
 CondTime-&gt;x.shape: torch.Size([2, 10, 12, 128, 128])
 encoded images shape: torch.Size([2, 10, 256, 32, 32])
 temp_enc out shape: torch.Size([2, 128, 32, 32])
Encode Timestep:(i=3)
 input shape: torch.Size([2, 10, 7, 128, 128])
 CondTime-&gt;x.shape: torch.Size([2, 10, 12, 128, 128])
 encoded images shape: torch.Size([2, 10, 256, 32, 32])
 temp_enc out shape: torch.Size([2, 128, 32, 32])
Encode Timestep:(i=4)
 input shape: torch.Size([2, 10, 7, 128, 128])
 CondTime-&gt;x.shape: torch.Size([2, 10, 12, 128, 128])
 encoded images shape: torch.Size([2, 10, 256, 32, 32])
 temp_enc out shape: torch.Size([2, 128, 32, 32])
res.shape=torch.Size([2, 5])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 5])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="metnet_splitter" class="doc_header"><code>metnet_splitter</code><a href="https://github.com/tcapelle/metnet_pytorch/tree/master/metnet_pytorch/model.py#L123" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>metnet_splitter</code>(<strong><code>m</code></strong>)</p>
</blockquote>
<p>A simple param splitter for MetNet</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 


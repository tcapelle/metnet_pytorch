{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94feea-b086-4350-a3da-70af88a5cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579fdf7-c9e8-47a9-b60c-84d47fe2140e",
   "metadata": {},
   "source": [
    "# Useful Layers\n",
    "> Some Pytorch layers needed for MetNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e008384-0d87-448d-82c8-1af22000b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from fastai.text.all import WeightDropout, RNNDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e52bcf-8fa8-40bc-8a2c-abf50d57eb9c",
   "metadata": {},
   "source": [
    "## ConvLSTM / ConvGRU layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde195af-72ff-4184-84e5-027a789b410b",
   "metadata": {},
   "source": [
    "### CGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4046b-16b2-459c-938e-c3e289f06683",
   "metadata": {},
   "source": [
    "https://github.com/jhhuang96/ConvLSTM-PyTorch/blob/master/ConvRNN.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5aa848-2ccd-4e63-9f99-428543a3467f",
   "metadata": {},
   "source": [
    "In a GRU cell the outputs and hidden are the same, last output must be equal to last hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ba571-4dd2-4720-a011-b0935d5ec3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvGRUCell(Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size=(3,3), bias=True, activation=F.tanh, batchnorm=False):\n",
    "        \"\"\"\n",
    "        Initialize ConvGRU cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "        self.input_dim          = input_dim\n",
    "        self.hidden_dim         = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, (tuple, list)) else [kernel_size]*2\n",
    "        self.padding     = self.kernel_size[0] // 2, self.kernel_size[1] // 2\n",
    "        self.bias        = bias\n",
    "        self.activation  = activation\n",
    "        self.batchnorm   = batchnorm\n",
    "\n",
    "\n",
    "        self.conv_zr = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=2 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        self.conv_h1 = nn.Conv2d(in_channels=self.input_dim,\n",
    "                              out_channels=self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        self.conv_h2 = nn.Conv2d(in_channels=self.hidden_dim,\n",
    "                              out_channels=self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def forward(self, input, h_prev=None):\n",
    "        #init hidden on forward\n",
    "        if h_prev is None:\n",
    "            h_prev = self.init_hidden(input)\n",
    "            \n",
    "        combined = torch.cat((input, h_prev), dim=1)  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = F.sigmoid(self.conv_zr(combined))\n",
    "\n",
    "        z, r = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "\n",
    "        h_ = self.activation(self.conv_h1(input) + r * self.conv_h2(h_prev))\n",
    "\n",
    "        h_cur = (1 - z) * h_ + z * h_prev\n",
    "\n",
    "        return h_cur\n",
    "    \n",
    "    def init_hidden(self, input): \n",
    "        bs, ch, h, w = input.shape\n",
    "        return one_param(self).new_zeros(bs, self.hidden_dim, h, w)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        #self.conv.reset_parameters()\n",
    "        nn.init.xavier_uniform_(self.conv_zr.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        self.conv_zr.bias.data.zero_()\n",
    "        nn.init.xavier_uniform_(self.conv_h1.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        self.conv_h1.bias.data.zero_()\n",
    "        nn.init.xavier_uniform_(self.conv_h2.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "        self.conv_h2.bias.data.zero_()\n",
    "\n",
    "        if self.batchnorm:\n",
    "            self.bn1.reset_parameters()\n",
    "            self.bn2.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1910e8-6add-4196-96b6-051b4160e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgru_cell = ConvGRUCell(16, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d65e3-459d-431c-bf99-69ffc274b3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 16, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgru_cell(torch.rand(1, 16, 16, 16)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa4aef-c4b2-4a64-b7b4-bc8c595b5b04",
   "metadata": {},
   "source": [
    "Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb8cd2-7a29-4d0b-9802-dfde519673db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvGRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, n_layers, batch_first=True, \n",
    "                 bias=True, activation=F.tanh, input_p=0.2, hidden_p=0.1, batchnorm=False):\n",
    "        super(ConvGRU, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, n_layers)\n",
    "        hidden_dim  = self._extend_for_multilayer(hidden_dim, n_layers)\n",
    "        activation  = self._extend_for_multilayer(activation, n_layers)\n",
    "\n",
    "        if not len(kernel_size) == len(hidden_dim) == len(activation) == n_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.input_p = input_p\n",
    "        self.hidden_p = hidden_p\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(self.n_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
    "\n",
    "            cell_list.append(ConvGRUCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias,\n",
    "                                          activation=activation[i],\n",
    "                                          batchnorm=batchnorm))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([nn.Dropout(hidden_p) for l in range(n_layers)])\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def __repr__(self): \n",
    "        s = f'ConvGru(in={self.input_dim}, out={self.hidden_dim[0]}, ks={self.kernel_size[0]}, '\n",
    "        s += f'n_layers={self.n_layers}, input_p={self.input_p}, hidden_p={self.hidden_p})'\n",
    "        return s\n",
    "    def forward(self, input, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor:\n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state:\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        input = self.input_dp(input)\n",
    "        cur_layer_input = torch.unbind(input, dim=int(self.batch_first))\n",
    "        \n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.get_init_states(cur_layer_input[0])\n",
    "\n",
    "        seq_len = len(cur_layer_input)\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list   = []\n",
    "        \n",
    "        for l, (gru_cell, hid_dp) in enumerate(zip(self.cell_list, self.hidden_dps)):\n",
    "            h = hidden_state[l]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h = gru_cell(input=cur_layer_input[t], h_prev=h)\n",
    "                output_inner.append(h)\n",
    "\n",
    "            cur_layer_input = torch.stack(output_inner)  #list to array\n",
    "            if l != self.n_layers: cur_layer_input = hid_dp(cur_layer_input)\n",
    "            last_state_list.append(h)\n",
    "\n",
    "        layer_output = torch.stack(output_inner, dim=int(self.batch_first))\n",
    "        last_state_list = torch.stack(last_state_list, dim=0)\n",
    "        return layer_output, last_state_list\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for c in self.cell_list:\n",
    "            c.reset_parameters()\n",
    "\n",
    "    def get_init_states(self, input):\n",
    "        init_states = []\n",
    "        for gru_cell in self.cell_list:\n",
    "            init_states.append(gru_cell.init_hidden(input))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or (isinstance(kernel_size, list)\n",
    "            and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ff2c2-0e22-4576-baf1-f22bc7ab4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgru = ConvGRU(16, 32, (3, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504af00-526b-4c3d-a1e1-5109f88675e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvGru(in=16, out=32, ks=(3, 3), n_layers=2, input_p=0.2, hidden_p=0.1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a64ff-b92e-403e-88ea-a385d7ad6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output, last_state_list = cgru(torch.rand(1,10,16,6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb6657-d6db-4156-878b-987086a0f581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 32, 6, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fb7e0-cd03-4f3f-830b-9bd4b8f87e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32, 6, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723c247-d052-4050-abc3-2fedb1c84f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output, last_state_list = cgru(torch.rand(1,10,16,6,6), last_state_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b97d6-dcf5-4403-b272-5ab61d2cd05b",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eca123-b604-4665-8e88-cc801c5d670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_layers.ipynb.\n",
      "Converted 01_model.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdfb82-14d3-4926-8eb3-dca3d5ac89d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
